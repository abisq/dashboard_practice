---
title: "Statistical Analysis Report for project protocol number MISIL1"
subtitle: "Multivariate models for biomarker data"
author: ""
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  rmdformats::downcute:
    use_bookdown: true
    toc_float: true
    number_sections: true
    fig_width: 8
    fig_height: 8
    fig_caption: true
    df_print: paged #specify rows.print = for each table
    code_folding: hide
editor_options: 
  chunk_output_type: console
---


<style>
body {
    position: absolute;
    left: 100px;
    max-width: 1100px;
    }
</style>




```{r setup, include=FALSE}
##--  Clear global environment
 rm(list = ls())
gc()
Sys.setenv(TZ='GMT')

#specify file paths
.libPaths("C:/Users/alessandra.bisquera/AppData/Local/R/win-library/4.2")
datpath <- "S:/Services/University of Cambridge/EXP22042/data"

library(tidyverse)
library(tableone)
library(kableExtra)
library(factoextra)
library(DT)
library(ggplot2)
library(randomForestSRC)
library(caret)
library(klaR)

"%ni%" <- Negate("%in%")

knitr::opts_chunk$set(warning = FALSE, message = FALSE)
options(knitr.kable.NA = '')

#import data - baseline, antibody and proteomics, and cytokines and the names of selected variables from previous univariate analyses
alldat <- read.csv(paste0(datpath,"/combinedat_June2024.csv")) %>%
mutate(Selected = ifelse(variable=="family_history_lung_cancer_label", 1,
ifelse(variable=="PSA",0, Selected)),#remove PSA and add family history as variable of interest
variable= str_remove_all(variable, "[:)-]"),
variable = ifelse(Dataset=="Cytokine" & variable=="AFP", "AFP_Cyt",
ifelse(Dataset=="Antibody" & variable=="AFP", "AFP_Ant", variable))
)

seldat <- alldat %>%
filter(Selected==1 & study_cohort_label != "Group C") %>%
mutate(outc= factor(ifelse(study_cohort_label=="Group B",1,0)))
selected <- seldat %>% distinct(Dataset, variable)

# get variable names
#an <- selected$variable
an <- selected$variable[(selected$Dataset == "ECDT" & selected$variable %in% c("Overall")) | selected$Dataset != "ECDT" ] #without zero variables

#### now get test data ###
testdat <- readxl::read_excel(paste0(datpath,"/CUH CDT study_result summary.xlsx"),
sheet="Results",col_types = "guess",col_names =T) %>%
dplyr::select(ssid,`patient cohort`,`malignant or benign`) %>%
inner_join(alldat %>% filter(variable %in% selected$variable), by="ssid") %>%
mutate(`malignant or benign` = ifelse(ssid %in% c("MSLCUH023","MSLRPH001", "MSLCUH033"), "malignant",
ifelse(ssid %in% c("MSLCUH035"), "benign", `malignant or benign`)),
outc = ifelse(`malignant or benign` == "malignant", 1,0),
Selected=1
) %>%
filter(study_cohort_label =="Group C" &  `malignant or benign` != "nk"  )

with(testdat, table(outc,`malignant or benign`, study_cohort_label, useNA="always"))

check <- testdat %>% distinct(ssid,`malignant or benign` )



# check univ screening of baseline data 
bdat <- readxl::read_excel(paste0(datpath,"/misil1_screening_baseline_310822 cleaned.xlsx")) %>% 
  mutate(Followup =as.numeric(date_completed -  date_consent))
name_bdat <-names(bdat)

bdat[name_bdat[c(4:21,97:99)]] <- lapply(bdat[name_bdat[c(4:21,97:99)]],
                                             function(x) ifelse(is.na(x), "No", x))

bdat <- bdat %>% filter(study_cohort_label != "Group C")

tab2 <- CreateTableOne(vars=c(name_bdat[c(23:56,59,61,63,65,67,69:96)]),
                       strata=c("study_cohort_label"), 
                       factorVars= "ecog_who_label",
                       data=bdat,test = T,addOverall = T)

tab2a <- data.frame(print(tab2,  catDigits = 1,contDigits = 1, missing=T, 
                         test=T, noSpaces=T, showAllLevels = T, varLabels=T,
                         printToggle = FALSE))

tab2a$labels <- gsub("X.*", NA,rownames(tab2a))
tab2a <- tab2a %>%  fill(labels) %>% 
  mutate(labels = str_replace_all(labels, c("..mean..SD.."="",
                                            "_label...." = "", 
                                            "_" = " ")),
         labels = str_to_title(labels),
         level = str_replace(level,"^$", "mean (sd)")
         )

tab2b <- data.frame(print(tab2$ContTable,contDigits = 1, missing=T,
                          nonnormal =T,minMax = TRUE,
                         test=T, noSpaces=T, showAllLevels = T, varLabels=T,
                         printToggle = FALSE))

tab2b$labels <- gsub("X.*", NA,rownames(tab2b))
tab2b <- tab2b %>%
  mutate(labels = str_replace_all(labels, c("_" = " ")),
         labels = str_to_title(labels),
         level = "median [min, max]")
  
tab2b$labels <- stringi::stri_replace_all_fixed(tab2b$labels, " (Median [Range])", "")

tab2a$id  <- 1:nrow(tab2a)
tab2b <- tab2b %>% left_join(tab2a %>% dplyr::select(labels, id)) %>% 
  filter(labels != "N")
tab2 <- full_join(tab2a,tab2b) %>% 
  arrange(id, labels,level) %>% 
  mutate(Group.A = ifelse(Group.A %in% c("0 (NaN)", "NA [Inf, -Inf]", "NaN (NA)"),
                          "", Group.A),
         Group.B = ifelse(Group.B %in% c("0 (NaN)", "NA [Inf, -Inf]", "NaN (NA)"),
                          "", Group.B)
         ) %>% 
  group_by(labels) %>% 
  fill(p, .direction ="down") %>% 
  ungroup() %>% 
  #filter(level %ni% c("No", "Don't know", "N/A")  | labels %in% c("Amyloidosis",  "Monoclonal Gammopathy", "Myeloma")) %>% #
  mutate(Missing = ifelse(substr(labels, 1,2) %in% c("B ", "C ", "Pn",
                                                     "Co", "He","St", "Dv",
                                                     "As", "Fv", "Fe","Tl",
                                                     "Kc") |  Missing == "0.0",
                          NA, Missing),
         labels = replace(labels, duplicated(labels), ''),
         labels = str_replace(labels, "Psa....", 'PSA')
  ) 


tab2 %>% 
  dplyr::select(labels, level, Group.A, Group.B, p, Missing) %>% 
  mutate(level = ifelse(labels=="N", "", 
                        ifelse(level %ni% c("mean (sd)", "median [min, max]"), 
                               paste0(level, " n (%)"), level)),
         labels = str_replace(labels, "Predicted", "%Predicted")) %>% 
  datatable(rownames=NULL,
            colnames=c("", "", "Negative control", "Positive control", "p-value", "Missing"),
            filter = "top",
            
            extensions = 'Buttons', options = list(dom = 'Bfrtip', buttons = c('csv'))
    
            ) %>% 
  formatStyle(columns=3:6, `text-align` = 'center') 



```





# Introduction 
This report presents the results of exploratory analyses of a number of multivariate models using data already available (antibodies, proteomic, cytokine, early CDT, methylation and baseline data). The overall plan is to estimate models for each biomarker modality separately and all together, and compare measures of model performance with the aim of identifying the ideal method/s and biomarker modality/ies which would best predict early stage lung cancer. 

The candidates selected from previous univariate analyses were chosen based on the magnitude of differences between the negative (A) and positive control (B) cohorts (using a high fold change) or significant p-values/q-values (< 0.05). These are listed in Table \@ref(tab:selectedtab) below:

```{r selectedtab, echo=FALSE,results="asis"}

prdat <- NULL
for (i in 1:length(an)) {
  
  impdat <- seldat[seldat$variable==an[i], c("study_cohort_label", "value")] 
  names(impdat) <- c("Group", "impvar")
  impdat$impvar <- as.numeric(ifelse(impdat$impvar %in% c("Yes", "H",  "Positve")  , 1,  ifelse(impdat$impvar
                                                                               %in% c("No", "N", "Negative","M", "HM") , 0, impdat$impvar)) )
  em1 <- impdat %>% 
    group_by(Group) %>%  
    summarize(est = paste0(round(mean(impvar, na.rm=T), 2), " (", 
                           round(sd(impvar, na.rm=T), 2), ")")) %>% 
    spread(Group, est) %>% 
    mutate(variable = an[i], Missing = sum(is.na(impdat[,"impvar"])))
  
  tdat <- testdat[testdat$variable==an[i], c("malignant or benign", "value")] 
  names(tdat) <- c("Group", "impvar")
  tdat$impvar <- as.numeric(ifelse(tdat$impvar %in% c("Yes", "H"), 1,  ifelse(tdat$impvar
                 %in% c("No", "N", "M", "HM") , 0, tdat$impvar)) )
    em2 <- tdat  %>% 
    group_by(Group) %>%  
    summarize(est = paste0(round(mean(impvar, na.rm=T), 2), " (", 
                           round(sd(impvar, na.rm=T), 2), ")")) %>% 
    spread(Group, est) %>% 
    mutate(variable = an[i], Missing2 = sum(is.na(impdat[,"impvar"])))
    
    pd <- cbind(em1, em2)
  
  prdat  <- rbind(prdat , pd) 
  
  rm(em1, em2, tdat, impdat, pd)
}


selsum <- prdat[,-3] %>% 
   left_join(selected, by="variable") %>% 
  mutate(across(c("Group A", "Group B","benign","malignant" ),
                function(x)(ifelse(variable == "family_history_lung_cancer_label" | Dataset=="ECDT",
                                   paste0(as.numeric(str_extract(string =x, pattern ="[^(]+"))*100, "%"), x))
                                   ))

discordant <- selsum %>%
  mutate(P1 = ifelse(as.numeric(str_extract(`Group B`, "[^(]+")) >
                     as.numeric(str_extract(`Group A`, "[^(]+")) |
                     as.numeric(str_extract(`Group B`, "[^%]+")) >
                     as.numeric(str_extract(`Group A`, "[^%]+")) ,1,0
                     ),
         P1 = ifelse(is.na(P1), 0, P1),
         M1 = ifelse(as.numeric(str_extract(malignant , "[^(]+")) >
                    as.numeric(str_extract(benign, "[^(]+")) |
                     as.numeric(str_extract(malignant, "[^%]+")) >
                     as.numeric(str_extract(benign, "[^%]+")),1,0
                     ),
         M1 = ifelse(is.na(M1), 0, M1),

         discordant = ifelse(P1 != M1, 1,0)
  )


cat("<table>",paste0("<caption>", "(#tab:selectedtab)","Summary of biomarker and baseline data. Values are displayed as mean (sd) or percentage as appropriate", "</caption>"),"</table>", sep ="\n")

selsum %>% 
  dplyr::select(Dataset, variable,`Group A`,`Group B`, benign, malignant ) %>% 
  mutate(Dataset = factor(Dataset, levels=unique(selected$Dataset))) %>% 
  arrange(Dataset) %>% 
  datatable(rownames=NULL,
            colnames=c("Database", "Feature", "Group A (n=30)  Negative control", "Group B (n=30)  Positive control", "Group C (n=8) Benign", "Group C (n=17) Malignant"),
            filter = "top"
            ) 


```



# Methods

## Datasets, variables and observations

The *training* dataset from which we will use to build multivariate models, has two patient cohorts consisting of current or former smokers, aged 50-80 years with ≥20 pack years smoking exposure, and are defined as follows:

• Group A, negative control cohort (n=30): Patients with no evidence of either lung cancer or an indeterminate pulmonary nodule on CT scan.

• Group B, positive control cohort (n=30): Patients with a high clinical suspicion or pathologically confirmed diagnosis of primary non-small cell lung cancer (stage IA).

Blood samples were processed across four different facilities, where antigen, proteomic, cytokine and methylation biomarkers were measured and quantified. The variables in these datasets, along with patient baseline clincial data,  were assessed in univariate models and selected for as described in Table \@ref(tab:selectedtab). 

For the purpose of our analyses, we will refer to cohort (A or B; Lung cancer yes/no) as the outcome variable and biomarkers and baseline data as the predictor variables. 


The *test* set comprises of Group C - 30 patients with a solid indeterminate pulmonary nodule (IPN) measuring 8mm-20mm without a histological diagnosis who were followed up over 5 years to determine if the nodules were malignant or benign. There are currently 5 patients with unknown outcomes, therefore only 25 patients are used for the test set. 

(Table \@ref(tab:selectedtab)) compares the characteristics across benign (n=8) vs malignant (n=17) patients in Group C. Some features such as family history of lung cancer and smoking pack years are unexpectedly lower in the malignant group. A further 41% of biomarkers are expressed discordant to what was observed for Group A vs B. This is most prominent for the antibody and methylation biomarkers with 90 out of 212 (42%) of the biomarkers discordant between the training and test data. 




## Data transformations
Due to the nature of the datasets the following pre-processing was employed:

**Proteomic data**: Missing values were imputed by half the minimum value prior to log2 transformations.

**Antigen data**: Biomarkers with mean foreground intensities (FG) < 0 across samples were filtered out. The remaining measurements were then log2 transformed then normalized using loess normalization. 

**Cytokine data**: Observations for each analyte were calculated according to the measured fluorescence intensity calculated using the standard curve. Any measurements out of range above the standard curve (OOR >) had values imputed using the maximum observed within the sample, while OOR < were imputed using the minimum value. Any OOR without specification of being above or below the curve were turned to missing, prior to the remaining values being log2 transformed. 

**Methylation data**: The log ratio of U and M values from cancer segment coordinates are used.


**Clinical/Baseline data**: No data pre-processing was employed. 

## Pre-checks
All predictors were checked for  percentage of unique data points to indicate whether that predictor has only one distinct value, whether the predictor is a near zero variance predictor, and whether predictors are highly correlated (*r* > 0.9). 





## Model Building 


Multivariate models were created for each biomarker modality using the preselected variables. In the following sections we describe the methods for consideration. The first two methods (logistic regression and Naïve Bayes Classification) create single models using frequentist and Bayesian approaches, while the last two (Random Forest and ADABoost) employ ensemble learning whereby predictions are made using a combination of models.

For all methods, the following measures of model performance will be presented using a spider/radar chart: Area Under the Curve (AUC), Accuracy, Sensitvity, Specificity, Positive Predictive Value (PPV; also known as precision in some R functions), and Negative Predictive Value. The AUC was usually created using the predicted response or posterior probabilities generated from the training dataset, while all other metrics were derived from confusion matrices. For ensemble methods and those fitting models using cross validation, the performance measures are the average taken across models. 


### 1. Logistic regression 
This is the most well known and utilized supervised learning algorithm. For this method predictors from each dataset/biomarker modality were added all together in a generalized linear model, under the  binomial family and a logit link function. Then, the most important variables were identified step-wise model selection by AIC. 

The coefficients of the final model were regularized using the LASSO procedure. 


The R package ‘glm’,  'MASS::stepAIC', 'glmnet::cv.glmnet' and 'pROC::roc' was used for this analysis. 


### 2. Naïve Bayes Classification

Naive Bayes methods is a supervised learning algorithm based on applying Bayes’ theorem with the “naive” assumption of conditional independence between every pair of features given the value of the class variable. The posterior probability (of the occurence of lung cancer) is derived using the Bayes formula summarized as $$posterior = \frac{prior * likelihood}{data}$$

All variables within each biomarker modality were used to calculate the posterior probabilities. The most important variables were identified using ROC curve analysis conducted on each predictor. The variable importance measure were scaled from 0-100 (100 being the most important), and those with a measure > 70 are presented. While these important variables are presented in the results, separate models with reduced variables (as per the logistic regression method) were not created due to the fact that variable importance was calculated for each individual predictor, and is not indicative of how well the predictor will perform when others are added into the model. 

The R package ‘caret::train’,  'caret::varImp' and 'pROC::roc' was used for this analysis. The models were trained using 10 fold cross validation. 



### 3. Random forest

Random Forest is a commonly used machine learning algorithm that combines the output of multiple Decision Trees to achieve a single result. Each tree is independent of each other in terms of the number of branches and the groups variables used. 

Unlike the first two methods, resampling with replacement (bagging) and variable selection (feature randomness) is inherent in the random forest algorithm, with the variables selected using minimal depth variable selection.

The models are optimized by selecting for the number of trees and number of variables used in each tree which stabilizes the out of bag error rate. 

The R package 'randomForestSRC::rfsrc' is used for this analysis, with a maximum number of 4000 trees specified. 


### 4. ADABoost

AdaBoost Algorithm (Adaptive Boosting), is similar to Random forest in that multiple decision trees are created to predict the outcome. However, while the random forest method trains individual models in a parallel way (in a process called bagging), in gradient boosting each model learns from the mistakes of the previous model, by weighting the instances in the training dataset based on the accuracy of previous classifications. All models/decision trees are then combined to form a strong performing model. Similar to random forest, the number of trees and depth of each tree will be optimized by minimizing the error rate. To further enhance how accuracy and performance is evaluated, 10-fold cross validation will be employed with the average metric across folds presented. All variables will be used to to create decision trees but, similar to Naive Bayes, variable importance will be evaluated using ROC curve analysis and those with a measure > 70 are presented.

The R package ‘caret::train’, 'caret::varImp' and 'pROC::roc' will be used for this analysis



## Model testing

The parameters derived from the models were used to create predicted probabilities for the outcomes in the test set. These predicted probabilities were used to build the  receiver operating characteristic (ROC) curve and derive the area under the curve (AUC) and the optimal cut-off point which maximizes the sensitivity and specificity. If there were multiple cut-off points, then the one that has the *highest specificity* was chosen.

Using the prescribed cut-off point for the predicted probabilities, the test set patients were classified as either having the outcome or not. These were then cross-tabulated against the observed outcome (benign/malignant) to derive the confusion matrix with additional performance metrics: accuracy, positive and negative predictive value. 


# Results


```{r allreg, echo=FALSE, include=F}

tempdat <- seldat %>% 
  filter(variable %in% an) %>% 
  mutate(value = as.numeric(ifelse(value %in% c("Yes", "H"), 1,  
                                      ifelse(value %in% c("No", "N", "M", "HM") , 0, value)) )
         ) %>% 
  dplyr::select(ssid, variable, value, outc) %>% 
  spread(variable, value) %>% 
  mutate_at(vars(matches("family_history")), factor)

tempdat <- na.omit(tempdat)

# format testdata 
tempdat2 <- testdat %>% 
  filter(variable %in% an) %>% 
  mutate(value = as.numeric(ifelse(value %in% c("Yes", "H"), 1,  
                                      ifelse(value %in% c("No", "N", "M", "HM") , 0, value)) )
         ) %>% 
  dplyr::select(ssid, variable, value, outc) %>% 
  spread(variable, value) %>% 
  mutate_at(vars(matches("family_history")), factor)


#logistic with stepwise selection
mod <- glm(as.formula(paste0("outc ~", paste(an, collapse=" + "))), data =tempdat, family="binomial") %>% MASS::stepAIC(trace = FALSE)

logcoef <- names(coef(mod)[-1])
check <- glm(as.formula(paste0("outc ~", paste(logcoef, collapse=" + "))), data =tempdat, family="binomial")


## lasso to regularize coefficients ##
set.seed(1)
amat <- model.matrix(as.formula(paste0("outc ~", paste(logcoef, collapse=" + "))), data =tempdat)
cv.out <- glmnet::cv.glmnet(amat,tempdat$outc,alpha=1,family="binomial",type.measure ="mse" )
plot(cv.out)
#min value of lambda
lambda_min <- cv.out$lambda.min
#best value of lambda
lambda_1se <- cv.out$lambda.1se
#regression coefficients
lcoef <- coef(cv.out,s=lambda_1se)
coeff <- lcoef@Dimnames[[1]]
coeff <- coeff[lcoef@i + 1]

options(na.action='na.pass')
tmat <- model.matrix(as.formula(paste0("outc ~", paste(logcoef, collapse=" + "))), data =tempdat2)

moda1 <- predict(cv.out,tmat,s=lambda_1se,type="response")
#moda1 <- predict(mod,tempdat2,type="response")
proc <- pROC::roc(factor(tempdat2$outc),as.numeric(moda1) ) 
proc2<- data.frame(sens=proc$sensitivities, spec=proc$specificities,co = proc$thresholds )

proc3 <- proc2 %>% 
  mutate(m=sens+spec) %>% 
  filter(m==max(m)) %>% 
  mutate(auc = proc$auc,
         auc_CI = paste(round(pROC::ci.auc(proc)[1],3), "-",round(pROC::ci.auc(proc)[3],3) ),
         nvars= length(coeff[-1]),
         vars =paste(coeff[-1], collapse=", "),
         model="Logistic regression with stepwise selection"
         ) %>% 
  filter(spec==max(spec)) #if more than one cut off, give the one with highest specificity

mod3 <- factor(ifelse(moda1> proc3$co,1,0))
cbind(mod3, tempdat2[, c("ssid", "outc")])
cm <- confusionMatrix(data=mod3,reference=factor(tempdat2$outc), positive="1")

moda  <- proc3 %>% 
  mutate(ppv = cm$byClass["Pos Pred Value"] , npv = cm$byClass["Neg Pred Value"], acc= cm$byClass["Balanced Accuracy"]) %>% 
  mutate_at(c("ppv", "npv", "acc"), function(x, na.rm = FALSE) 
    ifelse(proc3$sens != cm$byClass["Sensitivity"] | proc3$spec != cm$byClass["Specificity"], 1 - x, x) )  #reversed https://stackoverflow.com/questions/57512814/sensitivity-and-specificity-values-differ-using-two-different-r-package-caret-a
  



#####  naive bayes ###############

#varimp doesnt accept factor vars we'll have to do a workaround, this method also removes missing observations https://stackoverflow.com/questions/66386199/error-when-calculating-variable-importance-with-categorical-variables-using-the
x = tempdat[, an]
y = factor(ifelse(tempdat$outc=="1","Pos","Neg"))
dummy_data = data.frame(x,y)
dummy_data = data.frame(y = dummy_data$y,model.matrix(y~ 0+.,data=dummy_data))

mod = train(y~., data=dummy_data ,method="naive_bayes",preProcess="scale",trControl=trainControl(method='cv',number=10,
            classProbs=T, savePredictions = T),
            tuneGrid = data.frame(usekernel=TRUE,laplace = 1,adjust=1)
            ) #add laplace smoothing to remove the problem of zero probability https://towardsdatascience.com/laplace-smoothing-in-na%C3%AFve-bayes-algorithm-9c237a8bdece#:~:text=Laplace%20smoothing%20is%20a%20smoothing%20technique%20that%20helps%20tackle%20the,the%20positive%20and%20negative%20reviews.

x2 <-tempdat2[, an]
y2 <- factor(ifelse(tempdat2$outc==1,"Pos","Neg"))
dummy_data2=na.omit(data.frame(x2,y2))
tdat <-  data.frame(y2 = dummy_data2$y2,model.matrix(y2~ 0+.,data=dummy_data2))


vi <- varImp(mod, scale=T)$importance[2] %>% #scale to 0-100 and select top 70%
  #top_n(20) %>%
  filter(Pos > 70) %>% 
  arrange(desc(Pos)) 
vi <- paste0(rownames(vi)) 
vi <- vi[which(vi %ni% c("family_history_lung_cancer_label0" ))]


set.seed(1)
pred <- predict(mod, newdata = tdat[,-1], type="prob")
proc <- pROC::roc(dummy_data2$y2,as.numeric(pred[,2]) )
proc2<- data.frame(sens=proc$sensitivities, spec=proc$specificities,co = proc$thresholds )
proc3 <- proc2 %>%
  mutate(m=sens+spec) %>%
  filter(m==max(m)) %>%
  mutate(auc = proc$auc,
         auc_CI = paste(round(pROC::ci.auc(proc)[1],3), "-",round(pROC::ci.auc(proc)[3],3) ),
         nvars= length(vi),
         vars =paste(vi, collapse=", "),
         model="Naive Bayes with variable importance"
         ) %>%
 filter(spec==max(spec)) #if more than one cut off, give the one with highest specificity

pmod <- factor(ifelse(as.numeric(pred[,2]) > proc3$co,"Pos","Neg"))
cm <- confusionMatrix(data=pmod,reference=factor(tdat$y2), positive="Pos")


modb<- proc3 %>%
  mutate(ppv = cm$byClass["Pos Pred Value"] , npv = cm$byClass["Neg Pred Value"], acc= cm$byClass["Balanced Accuracy"]) %>% 
  mutate_at(c("ppv", "npv", "acc"), function(x, na.rm = FALSE) 
    ifelse(proc3$sens != cm$byClass["Sensitivity"] | proc3$spec != cm$byClass["Specificity"], 1 - x, x) )





#### random forest ####
rfmode <- rfsrc(y ~ .,data=dummy_data, tree.err = TRUE,importance = TRUE, ntree=4000)
vars <- var.select(object =rfmode,refit=TRUE,method =  "md", seed=1) #do not use vh.imp as this selection method is not repeatable https://github.com/kogalur/randomForestSRC/issues/67
vars$topvars
m1<- vars$rfsrc.refit.obj # model refitted with selected variables

plot(get.tree(m1, 3))
plot(get.tree(m1, 1050, target = "Pos"))

set.seed(1)
pred <- predict(m1 , newdata = dummy_data2)
proc <- pROC::roc(dummy_data2$y2 ,pred[["predicted"]][,"Pos"] )
proc2<- data.frame(sens=proc$sensitivities, spec=proc$specificities,co = proc$thresholds )
proc3 <- proc2 %>%
  mutate(m=sens+spec) %>%
  filter(m==max(m)) %>%
  mutate(auc = proc$auc,
          auc_CI = paste(round(pROC::ci.auc(proc)[1],3), "-",round(pROC::ci.auc(proc)[3],3) ),
         nvars= length(m1[["xvar.names"]]),
         vars =paste(m1[["xvar.names"]], collapse=", "),
         model="Random Forest with minimal depth variable selection"
         ) %>%
 filter(spec==max(spec)) #if more than one cut off, give the one with highest specificity

pmod <- factor(ifelse(pred[["predicted"]][,"Pos"] > proc3$co,"Pos","Neg"))
cm <- confusionMatrix(data=pmod,reference=factor(dummy_data2$y2), positive="Pos")

modc<- proc3 %>%
  mutate(ppv = cm$byClass["Pos Pred Value"] , npv = cm$byClass["Neg Pred Value"], acc= cm$byClass["Balanced Accuracy"]) %>% 
  mutate_at(c("ppv", "npv", "acc"), function(x, na.rm = FALSE) 
    ifelse(proc3$sens != cm$byClass["Sensitivity"] | proc3$spec != cm$byClass["Specificity"], 1 - x, x) )




### ADAboost ########
set.seed(1)
mod = train(y~., data=dummy_data,method='adaboost',preProcess="scale",
            trControl=trainControl(method='cv',number=10, classProbs = TRUE,savePredictions ='final') #final model
             )

vi <- varImp(mod, scale=T)$importance[2] %>% #scale to 0-100 and select top 70%
  #top_n(20) %>%
  filter(Pos > 70) %>% 
  arrange(desc(Pos)) 
vi <- paste0(rownames(vi)) 
vi <- vi[which(vi %ni% c("family_history_lung_cancer_label0" ))]


set.seed(1)
pred <- predict(mod, newdata = tdat[,-1], type="prob")
proc <- pROC::roc(tdat$y2,as.numeric(pred[,2]) )
proc2<- data.frame(sens=proc$sensitivities, spec=proc$specificities,co = proc$thresholds )
proc3 <- proc2 %>%
  mutate(m=sens+spec) %>%
  filter(m==max(m)) %>%
  mutate(auc = proc$auc,
         auc_CI = paste(round(pROC::ci.auc(proc)[1],3), "-",round(pROC::ci.auc(proc)[3],3) ),
         nvars= length(vi),
         vars =paste(vi, collapse=", "),
         model="ADABoost with variable importance") %>%
 filter(spec==max(spec)) #if more than one cut off, give the one with highest specificity

pmod <- factor(ifelse(as.numeric(pred[,2]) > proc3$co,"Pos","Neg"))
cm <- confusionMatrix(data=pmod,reference=factor(tdat$y2), positive="Pos")

modd<- proc3 %>%
  mutate(ppv = cm$byClass["Pos Pred Value"] , npv = cm$byClass["Neg Pred Value"], acc= cm$byClass["Balanced Accuracy"]) %>% 
  mutate_at(c("ppv", "npv", "acc"), function(x, na.rm = FALSE) 
    ifelse(proc3$sens != cm$byClass["Sensitivity"] | proc3$spec != cm$byClass["Specificity"], 1 - x, x) )


```




```{r adbpl, echo=FALSE,fig.cap="Performance metrics of Adaboost", figure.height = 10, figure.width = 12}

allmods <- rbind(moda, modb, modc, modd) %>% 
   mutate(sumperf = auc+acc+sens+spec+ppv+npv, 
          label = str_extract(model, "(\\w+\\s+\\w+)"),
          label = str_remove(label, "with"),
          
          #update March 2025 to include LR
          LRp = sens/(1-spec),
          LRn = (1-sens)/spec
          
          ) %>% 
   arrange(desc(sumperf)) %>% 
  relocate(label,  nvars, sumperf , auc,auc_CI, acc, sens, spec, ppv, npv, LRp, LRn)

commonvars <- str_trim(unlist(str_split(allmods$vars, ",")))
commonvars <- data.frame(table(commonvars)) %>% 
              rename(variable=commonvars) %>% 
              left_join(selected) %>% 
              arrange(desc(Freq)) 

ggradar::ggradar(allmods[,c(1,4, 6:10)],
                 legend.title = "Model type", legend.position = "right",
                 axis.labels = c("AUC","Accuracy", "Sensitivity", "Specificity", "PPV", "NPV"),
                 group.line.width = 0.7,group.point.size = 3,
                 group.colours = c("#16213D", "#A1B9E0", "#6B8BE5", "#DA8280")
) +
  theme(plot.margin = unit(c(0,0,0,0), "cm"))

```



```{r allt, echo=FALSE,results="asis"}
cat("<table>",paste0("<caption>", "(#tab:alltab)","Comparisons of performance metrics", "</caption>"),"</table>", sep ="\n")

allmods[,c(1:12)] %>%
  datatable(rownames=NULL,
            colnames=c("Model", "Number of selected variables", "Sum of performance indices", "AUC", "AUC 95% CI",  "Accuracy","Sensitivity", "Specificity", "PPV", "NPV",
                       "LR+", "LR-"),
            filter = "top",
            
            extensions = 'Buttons', options = list(dom = 'Bfrtip', buttons = c('csv'))
    
            ) %>% 
  formatStyle(columns=3:9, `text-align` = 'center') %>% 
  #formatStyle(columns=2,  fontSize = '8pt') %>% 
  formatRound(columns=c(3:4,6:12), digits= 3)


cat("<table>",paste0("<caption>", "(#tab:alltab2)","Final variables included", "</caption>"),"</table>", sep ="\n")

allmods[,c("label","nvars","vars")] %>%
  datatable(rownames=NULL,
            colnames=c("Model", "Number of selected variables", "Variables selected"),
            filter = "top"
            ) %>% 
  formatStyle(columns=3,  fontSize = '8pt')

```



```{r comt, echo=FALSE,results="asis"}

cat("<table>",paste0("<caption>", "(#tab:comvars)","Top predictors", "</caption>"),"</table>", sep ="\n")

commonvars %>%
  datatable(rownames=NULL,
            colnames=c(" ", "Number of models indicating predictor"),
            filter = "top"
            ) %>% 
  formatStyle(columns=2, `text-align` = 'center') 

```



# Visualisation of risk scores

```{r riskpl, echo=FALSE,fig.cap="Predicted probabilities resulting from the logistic model with lasso regularization", figure.height = 10, figure.width = 20,results="asis"}
set.seed(1)
#pred <- predict(m1 , newdata = tempdat2)
vars <- unlist(str_split(moda$vars, ", "))

rf_pred <- data.frame(ID = tempdat2$ssid, outc =tempdat2$outc, risk=as.numeric(moda1), tempdat2[, vars])


ggplot(data=rf_pred, aes(x= risk, col=factor(outc), fill=factor(outc))) +
    geom_histogram(bins=40, color="#e9ecef", alpha=0.6, position = 'identity') +
    scale_fill_manual(values=c("#16213D","#DA8280"), labels=c("Benign", "Malignant")) +
    labs(fill="", x="Risk score", y="Number of patients",
         subtitle = paste0("AUC = ", round(moda$auc*100,1), "%, Accuracy = ", round(moda$acc*100,1), "%, Sens= ", round(moda$sens*100,1), "%, Spec = ", round(moda$spec*100,1), "%, PPV = ",round(moda$ppv*100,1), "%, NPV = ", round(moda$npv*100,1), "%"))+ 
   theme_minimal()+
  theme(legend.position="top")  
```


```{r rt, echo=FALSE,results="asis"}
cat("<table>",paste0("<caption>", "(#tab:risktab)","The test dataset (Group C) with predicted risk, along with selected variables from the random forest model", "</caption>"),"</table>", sep ="\n")


rf_pred %>%
  datatable(rownames=NULL,
            filter = "top",
            extensions = 'Buttons', 
            options = list(dom = 'Bfrtip', 
                           buttons = c('csv'),
                           pageLength = 29)
    
            ) %>% 
  formatRound(columns=3:ncol(rf_pred), digits= 3)



```


# PCA before and after selected models

Principal component analyses were carried out using all variables (241), and only variables selected in the final model(9).

Fig 5.1 below shows the plots before modelling/variable selection explains 39.2% of the total variance in the first two components. After variable selection, the 9 selected variables retains 64.1% of the total variance in the first two components, almost doubling the amount of information retained and increasing the separation of the scores between positive (malignant) and negative (benign) subjects (Fig 5.2). 

The 7 of the 9 variables are on the left side of the biplot, increasing values indicating a higher likelihood of malignancy, while higher values of PSIP1 and A0A087WSZ0 (on the right side of the biplot) is associated with patients with benign nodules. 


```{r pc, echo=FALSE, include=F}

#pca on test data
pcd <- prcomp(tdat[,-1], center = TRUE, scale. = TRUE)
summary(pcd)

befpl <- factoextra::fviz_pca_biplot(pcd,axes = c(1,2), col.ind = tdat$y2,repel = TRUE, 
                                     select.var = list(contrib = 10), title="PCA before variable selection (24.3% total variance)")

#pca after variable selection
tdat2 <- na.omit(rf_pred) %>% mutate(outc=factor(outc, levels=c(0,1), labels=c("Neg", "Pos")))
pcd2 <- prcomp(tdat2[,4:ncol(tdat2)], center = TRUE, scale. = TRUE)
summary(pcd2)

aftpl <- factoextra::fviz_pca_biplot(pcd2,axes = c(1,2), col.ind =tdat2$outc ,repel = TRUE,
                                     title="PCA after variable selection (44.9% total variance)")



#boxplot of pc scores between groups
scoredat <- data.frame(outc= tdat$y2, pcd$x[,1:2])
scoredat2 <- data.frame(outc= tdat2$outc, pcd2$x[,1:2])


scorepl1 <- ggplot(data=scoredat, aes(x=outc, y= PC1, fill=outc)) +
  geom_boxplot( ) +
  labs(x="", y="Scores in Dimension 1", title="PC scores before variable selection")+
  geom_point(size = 3, shape = 21, position = position_jitterdodge()) +
  theme_minimal() +
  theme(legend.position ="none") 



scorepl2 <- ggplot(data=scoredat2, aes(x=outc, y= PC1, fill=outc)) +
  geom_boxplot( ) +
  labs(x="", y="Scores in Dimension 1", title="PC scores after variable selection")+
  geom_point(size = 3, shape = 21, position = position_jitterdodge()) +
  theme_minimal() +
  theme(legend.position ="none") 





```


```{r pcpl, echo=FALSE,fig.cap="Principal component Analysis before and after model and variable selection", figure.height = 10, figure.width = 20,results="asis"}

gridExtra::grid.arrange(befpl, aftpl)



gridExtra::grid.arrange(scorepl1, scorepl2)



```





<!--

-->
